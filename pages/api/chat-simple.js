// ç®€åŒ–ç‰ˆèŠå¤©API - çº¯JavaScriptï¼Œç¡®ä¿Vercelå…¼å®¹
const OpenAI = require('openai')

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
})

export default async function handler(req, res) {
  // åªå…è®¸POSTè¯·æ±‚
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' })
  }

  try {
    // è§£æè¯·æ±‚æ•°æ®
    const { message, model = 'gpt-4o-mini', context = [] } = req.body

    if (!message) {
      return res.status(400).json({ error: 'Message is required' })
    }

    console.log('ğŸ¤– å¤„ç†èŠå¤©è¯·æ±‚:', { message, model })

    // æ„å»ºæ¶ˆæ¯æ•°ç»„
    const messages = [
      ...context,
      { role: 'user', content: message }
    ]

    // è°ƒç”¨OpenAI API
    const startTime = Date.now()
    const completion = await openai.chat.completions.create({
      model,
      messages,
      max_tokens: 2000,
      temperature: 0.7,
    })

    const latencyMs = Date.now() - startTime
    const content = completion.choices[0]?.message?.content

    if (!content) {
      throw new Error('No response from AI')
    }

    console.log('âœ… AIå“åº”æˆåŠŸ:', { latencyMs, model })

    // è¿”å›å“åº”
    return res.status(200).json({
      success: true,
      response: content,
      model: completion.model,
      latencyMs,
      usage: completion.usage
    })

  } catch (error) {
    console.error('âŒ èŠå¤©APIé”™è¯¯:', error)
    
    // è¿”å›å‹å¥½çš„é”™è¯¯å“åº”
    let errorMessage = 'æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚'
    
    if (error.status === 401) {
      errorMessage = 'APIå¯†é’¥é…ç½®é”™è¯¯'
    } else if (error.status === 429) {
      errorMessage = 'APIè°ƒç”¨é¢‘ç‡è¶…é™ï¼Œè¯·ç¨åé‡è¯•'
    } else if (error.status === 402) {
      errorMessage = 'OpenAIè´¦æˆ·ä½™é¢ä¸è¶³'
    }

    return res.status(200).json({
      success: true,
      response: errorMessage,
      model: 'fallback',
      latencyMs: 0
    })
  }
}